{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5b01c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loaded 276 chunks in 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c6f005544649e0ac8d1d6282c0fcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Generated embeddings in 8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saved index in 3.3s\n",
      "\n",
      "âœ… Total time: 11.4 seconds\n",
      "ðŸš€ Speed: 24.2 docs/sec\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Fast Embedding Generation\n",
    "# ![Optimized Pipeline](visuals/optimized_flow.png)\n",
    "\n",
    "# %%\n",
    "# Install only what's needed\n",
    "!pip install -U --quiet langchain-huggingface sentence-transformers faiss-cpu\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer  # Direct usage for better performance\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Disable unnecessary warnings\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "\n",
    "# %%\n",
    "def fast_embed(chunks, model_name=\"all-MiniLM-L6-v2\", batch_size=32):\n",
    "    \"\"\"Optimized embedding generation\"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    texts = [c.page_content for c in chunks]\n",
    "    return model.encode(texts, batch_size=batch_size, show_progress_bar=True)\n",
    "\n",
    "# %%\n",
    "# Main Execution\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # 1. Load processed chunks\n",
    "    with open(\"../processed_data/chunks.pkl\", \"rb\") as f:\n",
    "        chunks = pickle.load(f)\n",
    "    print(f\"ðŸ“‚ Loaded {len(chunks)} chunks in {time.time()-start_time:.1f}s\")\n",
    "    \n",
    "    # 2. Fast embedding\n",
    "    embed_start = time.time()\n",
    "    embeddings = fast_embed(chunks)\n",
    "    print(f\"âš¡ Generated embeddings in {time.time()-embed_start:.1f}s\")\n",
    "    \n",
    "    # 3. Create FAISS index\n",
    "    index_start = time.time()\n",
    "    db = FAISS.from_embeddings(\n",
    "        text_embeddings=list(zip([c.page_content for c in chunks], embeddings)),\n",
    "        embedding=SentenceTransformer(\"all-MiniLM-L6-v2\")  # Wrapper for FAISS compatibility\n",
    "    )\n",
    "    db.save_local(\"../faiss_store\")\n",
    "    print(f\"ðŸ’¾ Saved index in {time.time()-index_start:.1f}s\")\n",
    "    \n",
    "    print(f\"\\nâœ… Total time: {time.time()-start_time:.1f} seconds\")\n",
    "    print(f\"ðŸš€ Speed: {len(chunks)/(time.time()-start_time):.1f} docs/sec\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e15421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Top 3 results for query:\n",
      "\n",
      "--- Result 1 ---\n",
      "statements and any information in addition thereto supplied to the Company by the Insured or on  \n",
      "Insuredâ€Ÿs behalf. \n",
      " \n",
      "4. â€œInsured Premisesâ€ means the place(s) declared for insurance and named in the Schedule attached \n",
      "to the Policy. \n",
      " \n",
      "5. â€œPolicyâ€ means the Policy Booklet, the Schedule, the Proposal and any applicable endorsements or \n",
      "memoranda. The Policy contains the details of the extent of the cover available to the Insured, what \n",
      "is excluded from the cover and the conditions, warranties ba...\n",
      "\n",
      "--- Result 2 ---\n",
      "Loss, and We pay You the full Sum Insured for such item, the insurance cover  for that item will \n",
      "automatically end. If We pay the total Sum Insured for any claim, this Policy will end. \n",
      "f. Effect of death: If You are an individual, in the event of Your unfortunate death, the Insurance \n",
      "Covers that You have purchased will continue for the benefit of Your legal representative/s during \n",
      "the Policy Period subject to all the terms and conditions of this Section. \n",
      "g. Policy not invalidated: The Polic...\n",
      "\n",
      "--- Result 3 ---\n",
      "You will be responsible for the difference and You will bear a proportionate share of the loss. \n",
      "5. Underinsurance will not apply to Cover for Specific Contents. \n",
      "Note: The cost for Reinstatement of additions made to Insured Property during the Policy Period will be \n",
      "reckoned from the date of addition. \n",
      " \n",
      " \n",
      "Clause G. Conditions \n",
      "I) Your Obligations \n",
      "1. Make true and full disclosure in the proposal and related documents \n",
      "i. You have a duty of disclosure to tell Us everything You know, or could re...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Use embedding wrapper (not raw model)\n",
    "embedding_function = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")\n",
    "\n",
    "# Load FAISS with correct embedding wrapper\n",
    "db = FAISS.load_local(\n",
    "    \"../faiss_store\",\n",
    "    embeddings=embedding_function,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Query\n",
    "query = \"What does this insurance policy cover?\"\n",
    "results = db.similarity_search(query, k=3)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nðŸ” Top 3 results for query:\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\\n{doc.page_content[:500]}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
